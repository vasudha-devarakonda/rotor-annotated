Traceback (most recent call last):
  File "/home/cc/rotor-annotated/./train_llm.py", line 1, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
mv: cannot stat 'test.txt': No such file or directory
Traceback (most recent call last):
  File "/home/cc/rotor-annotated/./train_llm.py", line 1, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
mv: cannot stat 'test.txt': No such file or directory
Traceback (most recent call last):
  File "/home/cc/rotor-annotated/./train_llm.py", line 1, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
mv: cannot stat 'test.txt': No such file or directory
Traceback (most recent call last):
  File "/home/cc/rotor-annotated/./train_llm.py", line 1, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
mv: cannot stat 'test.txt': No such file or directory
Traceback (most recent call last):
  File "/home/cc/rotor-annotated/./train_llm.py", line 1, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
mv: cannot stat 'test.txt': No such file or directory
Traceback (most recent call last):
  File "/home/cc/rotor-annotated/./train_llm.py", line 1, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
mv: cannot stat 'test.txt': No such file or directory
Traceback (most recent call last):
  File "/home/cc/rotor-annotated/./train_llm.py", line 1, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
mv: cannot stat 'test.txt': No such file or directory
Traceback (most recent call last):
  File "/home/cc/rotor-annotated/./train_llm.py", line 1, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
mv: cannot stat 'test.txt': No such file or directory
Traceback (most recent call last):
  File "/home/cc/rotor-annotated/./train_llm.py", line 1, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
mv: cannot stat 'test.txt': No such file or directory
/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.
You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (0), or the `sep_token_id` (None), and your input is not padded.
Using GPU device 0
Using device: cuda
50304
Traceback (most recent call last):
  File "/home/cc/rotor-annotated/./train_llm.py", line 298, in <module>
    loss_hf, mem_loss = test_model_memory(model, sample, labels,device)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/rotor-annotated/./train_llm.py", line 185, in test_model_memory
    outputs = model(input_ids)
              ^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 1034, in forward
    outputs = self.gpt_neox(
              ^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 925, in forward
    outputs = layer(
              ^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 690, in forward
    attention_layer_outputs = self.attention(
                              ^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 211, in forward
    attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 268, in _attn
    attn_scores = torch.baddbmm(
                  ^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 
mv: cannot stat 'test.txt': No such file or directory
/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.
You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (0), or the `sep_token_id` (None), and your input is not padded.
Using GPU device 0
Using device: cuda
50304
Traceback (most recent call last):
  File "/home/cc/rotor-annotated/./train_llm.py", line 298, in <module>
    loss_hf, mem_loss = test_model_memory(model, sample, labels,device)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/rotor-annotated/./train_llm.py", line 185, in test_model_memory
    outputs = model(input_ids)
              ^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 1034, in forward
    outputs = self.gpt_neox(
              ^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 925, in forward
    outputs = layer(
              ^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 690, in forward
    attention_layer_outputs = self.attention(
                              ^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 211, in forward
    attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 268, in _attn
    attn_scores = torch.baddbmm(
                  ^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 
mv: cannot stat 'test.txt': No such file or directory
/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.
You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (0), or the `sep_token_id` (None), and your input is not padded.
Using GPU device 0
Using device: cuda
50304
Traceback (most recent call last):
  File "/home/cc/rotor-annotated/./train_llm.py", line 298, in <module>
    loss_hf, mem_loss = test_model_memory(model, sample, labels,device)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/rotor-annotated/./train_llm.py", line 185, in test_model_memory
    outputs = model(input_ids)
              ^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 1034, in forward
    outputs = self.gpt_neox(
              ^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 925, in forward
    outputs = layer(
              ^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 690, in forward
    attention_layer_outputs = self.attention(
                              ^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 211, in forward
    attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 268, in _attn
    attn_scores = torch.baddbmm(
                  ^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 
mv: cannot stat 'test.txt': No such file or directory
/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Using GPU device 0
Using device: cuda
50272
Traceback (most recent call last):
  File "/home/cc/rotor-annotated/./train_llm.py", line 298, in <module>
    loss_hf, mem_loss = test_model_memory(model, sample, labels,device)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/rotor-annotated/./train_llm.py", line 185, in test_model_memory
    outputs = model(input_ids)
              ^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/opt/modeling_opt.py", line 1120, in forward
    outputs = self.model.decoder(
              ^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/opt/modeling_opt.py", line 886, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/opt/modeling_opt.py", line 527, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/opt/modeling_opt.py", line 207, in forward
    attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len) + attention_mask
                   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 
mv: cannot stat 'test.txt': No such file or directory
/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Using GPU device 0
Using device: cuda
50272
Traceback (most recent call last):
  File "/home/cc/rotor-annotated/./train_llm.py", line 298, in <module>
    loss_hf, mem_loss = test_model_memory(model, sample, labels,device)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/rotor-annotated/./train_llm.py", line 185, in test_model_memory
    outputs = model(input_ids)
              ^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/opt/modeling_opt.py", line 1120, in forward
    outputs = self.model.decoder(
              ^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/opt/modeling_opt.py", line 886, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/opt/modeling_opt.py", line 527, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/opt/modeling_opt.py", line 207, in forward
    attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len) + attention_mask
                   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 
mv: cannot stat 'test.txt': No such file or directory
/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Using GPU device 0
Using device: cuda
50272
Traceback (most recent call last):
  File "/home/cc/rotor-annotated/./train_llm.py", line 298, in <module>
    loss_hf, mem_loss = test_model_memory(model, sample, labels,device)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/rotor-annotated/./train_llm.py", line 185, in test_model_memory
    outputs = model(input_ids)
              ^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/opt/modeling_opt.py", line 1120, in forward
    outputs = self.model.decoder(
              ^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/opt/modeling_opt.py", line 886, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/opt/modeling_opt.py", line 527, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/opt/modeling_opt.py", line 207, in forward
    attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len) + attention_mask
                   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 
mv: cannot stat 'test.txt': No such file or directory
/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.
You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.
Using GPU device 0
Using device: cuda
50257
Traceback (most recent call last):
  File "/home/cc/rotor-annotated/./train_llm.py", line 298, in <module>
    loss_hf, mem_loss = test_model_memory(model, sample, labels,device)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/rotor-annotated/./train_llm.py", line 185, in test_model_memory
    outputs = model(input_ids)
              ^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 1305, in forward
    transformer_outputs = self.transformer(
                          ^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 1119, in forward
    outputs = block(
              ^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 617, in forward
    attn_outputs = self.attn(
                   ^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 347, in forward
    attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 199, in _attn
    attn_weights = torch.matmul(query, key.transpose(-1, -2))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 
mv: cannot stat 'test.txt': No such file or directory
/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.
You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.
Using GPU device 0
Using device: cuda
50257
Traceback (most recent call last):
  File "/home/cc/rotor-annotated/./train_llm.py", line 298, in <module>
    loss_hf, mem_loss = test_model_memory(model, sample, labels,device)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/rotor-annotated/./train_llm.py", line 185, in test_model_memory
    outputs = model(input_ids)
              ^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 1305, in forward
    transformer_outputs = self.transformer(
                          ^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 1119, in forward
    outputs = block(
              ^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 617, in forward
    attn_outputs = self.attn(
                   ^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 347, in forward
    attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 199, in _attn
    attn_weights = torch.matmul(query, key.transpose(-1, -2))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 
mv: cannot stat 'test.txt': No such file or directory
/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.
You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.
Using GPU device 0
Using device: cuda
50257
Traceback (most recent call last):
  File "/home/cc/rotor-annotated/./train_llm.py", line 298, in <module>
    loss_hf, mem_loss = test_model_memory(model, sample, labels,device)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/rotor-annotated/./train_llm.py", line 185, in test_model_memory
    outputs = model(input_ids)
              ^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 1305, in forward
    transformer_outputs = self.transformer(
                          ^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 1119, in forward
    outputs = block(
              ^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 617, in forward
    attn_outputs = self.attn(
                   ^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 347, in forward
    attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cc/miniconda3/envs/pytorch-2.3.0-env/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 199, in _attn
    attn_weights = torch.matmul(query, key.transpose(-1, -2))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 
mv: cannot stat 'test.txt': No such file or directory
