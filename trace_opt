>>OPTForCausalLM--0
  >>OPTDecoder-model.decoder-2
  >>TokenEmbedding-OPTForCausalLM-token_emb-
    >>Embedding-model.decoder.embed_tokens-3
------>
embedding-0
<------
    <<Embedding-model.decoder.embed_tokens-3
    >>OPTLearnedPositionalEmbedding-model.decoder.embed_positions-4
------>
embedding-1
<------
    <<OPTLearnedPositionalEmbedding-model.decoder.embed_positions-4
    >>Linear-model.decoder.project_in-6
------>
t-2
<------
------>
view-3
<------
------>
mm-4
<------
------>
_unsafe_view-5
<------
    <<Linear-model.decoder.project_in-6
------>
add-6
<------
    <<TokenEmbedding-OPTForCausalLM-token_emb-
      >>OPTDecoderLayer-model.decoder.layers.0-8
        >>OPTAttention-model.decoder.layers.0.self_attn-9
          >>Linear-model.decoder.layers.0.self_attn.q_proj-12
------>
view-7
<------
------>
t-8
<------
------>
addmm-9
<------
------>
view-10
<------
          <<Linear-model.decoder.layers.0.self_attn.q_proj-12
------>
mul-11
<------
          >>Linear-model.decoder.layers.0.self_attn.k_proj-10
------>
view-12
<------
------>
t-13
<------
------>
addmm-14
<------
------>
view-15
<------
          <<Linear-model.decoder.layers.0.self_attn.k_proj-10
------>
view-16
<------
------>
transpose-17
<------
------>
clone-18
<------
          >>Linear-model.decoder.layers.0.self_attn.v_proj-11
------>
view-19
<------
------>
t-20
<------
------>
addmm-21
<------
------>
view-22
<------
          <<Linear-model.decoder.layers.0.self_attn.v_proj-11
------>
view-23
<------
------>
transpose-24
<------
------>
clone-25
<------
------>
view-26
<------
------>
transpose-27
<------
------>
clone-28
<------
------>
view-29
<------
------>
view-30
<------
------>
view-31
<------
------>
transpose-32
<------
------>
bmm-33
<------
------>
view-34
<------
------>
add-35
<------
------>
maximum-36
<------
------>
view-37
<------
------>
_softmax-38
<------
------>
bmm-39
<------
------>
view-40
<------
------>
transpose-41
<------
------>
clone-42
<------
------>
_unsafe_view-43
<------
          >>Linear-model.decoder.layers.0.self_attn.out_proj-13
------>
view-44
<------
------>
t-45
<------
------>
addmm-46
<------
------>
view-47
<------
          <<Linear-model.decoder.layers.0.self_attn.out_proj-13
        <<OPTAttention-model.decoder.layers.0.self_attn-9
------>
native_dropout-48
<------
------>
add-49
<------
        >>LayerNorm-model.decoder.layers.0.self_attn_layer_norm-15
------>
native_layer_norm-50
<------
        <<LayerNorm-model.decoder.layers.0.self_attn_layer_norm-15
------>
view-51
<------
        >>Linear-model.decoder.layers.0.fc1-16
------>
t-52
<------
------>
addmm-53
<------
        <<Linear-model.decoder.layers.0.fc1-16
        >>ReLU-model.decoder.layers.0.activation_fn-14
------>
relu-54
<------
        <<ReLU-model.decoder.layers.0.activation_fn-14
        >>Linear-model.decoder.layers.0.fc2-17
------>
t-55
<------
------>
addmm-56
<------
        <<Linear-model.decoder.layers.0.fc2-17
------>
native_dropout-57
<------
------>
add-58
<------
------>
view-59
<------
        >>LayerNorm-model.decoder.layers.0.final_layer_norm-18
------>
native_layer_norm-60
<------
        <<LayerNorm-model.decoder.layers.0.final_layer_norm-18
      <<OPTDecoderLayer-model.decoder.layers.0-8
      >>OPTDecoderLayer-model.decoder.layers.1-19
        >>OPTAttention-model.decoder.layers.1.self_attn-20
          >>Linear-model.decoder.layers.1.self_attn.q_proj-23
------>
view-61
<------
------>
t-62
<------
------>
addmm-63
<------
------>
view-64
<------
          <<Linear-model.decoder.layers.1.self_attn.q_proj-23
------>
mul-65
<------
          >>Linear-model.decoder.layers.1.self_attn.k_proj-21
------>
view-66
<------
------>
t-67
<------
------>
addmm-68
<------
------>
view-69
<------
          <<Linear-model.decoder.layers.1.self_attn.k_proj-21
------>
view-70
<------
------>
transpose-71
<------
------>
clone-72
<------
          >>Linear-model.decoder.layers.1.self_attn.v_proj-22
------>
view-73
<------
------>
t-74
<------
------>
addmm-75
<------
------>
view-76
<------
          <<Linear-model.decoder.layers.1.self_attn.v_proj-22
------>
view-77
<------
------>
transpose-78
<------
------>
clone-79
<------
------>
view-80
<------
------>
transpose-81
<------
------>
clone-82
<------
------>
view-83
<------
------>
view-84
<------
------>
view-85
<------
------>
transpose-86
<------
------>
bmm-87
<------
------>
view-88
<------
------>
add-89
<------
------>
maximum-90
<------
------>
view-91
<------
------>
_softmax-92
<------
------>
bmm-93
<------
------>
view-94
<------
------>
transpose-95
<------
------>
clone-96
<------
------>
_unsafe_view-97
<------
          >>Linear-model.decoder.layers.1.self_attn.out_proj-24
------>
view-98
<------
------>
t-99
<------
------>
addmm-100
<------
------>
view-101
<------
          <<Linear-model.decoder.layers.1.self_attn.out_proj-24
        <<OPTAttention-model.decoder.layers.1.self_attn-20
------>
native_dropout-102
<------
------>
add-103
<------
        >>LayerNorm-model.decoder.layers.1.self_attn_layer_norm-26
------>
native_layer_norm-104
<------
        <<LayerNorm-model.decoder.layers.1.self_attn_layer_norm-26
------>
view-105
<------
        >>Linear-model.decoder.layers.1.fc1-27
------>
t-106
<------
------>
addmm-107
<------
        <<Linear-model.decoder.layers.1.fc1-27
        >>ReLU-model.decoder.layers.1.activation_fn-25
------>
relu-108
<------
        <<ReLU-model.decoder.layers.1.activation_fn-25
        >>Linear-model.decoder.layers.1.fc2-28
------>
t-109
<------
------>
addmm-110
<------
        <<Linear-model.decoder.layers.1.fc2-28
------>
native_dropout-111
<------
------>
add-112
<------
------>
view-113
<------
        >>LayerNorm-model.decoder.layers.1.final_layer_norm-29
------>
native_layer_norm-114
<------
        <<LayerNorm-model.decoder.layers.1.final_layer_norm-29
      <<OPTDecoderLayer-model.decoder.layers.1-19
      >>OPTDecoderLayer-model.decoder.layers.2-30
        >>OPTAttention-model.decoder.layers.2.self_attn-31
          >>Linear-model.decoder.layers.2.self_attn.q_proj-34
------>
view-115
<------
------>
t-116
<------
------>
addmm-117
<------
------>
view-118
<------
          <<Linear-model.decoder.layers.2.self_attn.q_proj-34
------>
mul-119
<------
          >>Linear-model.decoder.layers.2.self_attn.k_proj-32
------>
view-120
<------
------>
t-121
<------
------>
addmm-122
<------
------>
view-123
<------
          <<Linear-model.decoder.layers.2.self_attn.k_proj-32
------>
view-124
<------
------>
transpose-125
<------
------>
clone-126
<------
          >>Linear-model.decoder.layers.2.self_attn.v_proj-33
------>
view-127
<------
------>
t-128
<------
------>
addmm-129
<------
------>
view-130
<------
          <<Linear-model.decoder.layers.2.self_attn.v_proj-33
------>
view-131
<------
------>
transpose-132
<------
------>
clone-133
<------
------>
view-134
<------
------>
transpose-135
<------
------>
clone-136
<------
------>
view-137
<------
------>
view-138
<------
------>
view-139
<------
------>
transpose-140
<------
------>
bmm-141
<------
------>
view-142
<------
------>
add-143
<------
------>
maximum-144
<------
------>
view-145
<------
------>
_softmax-146
<------
------>
bmm-147
<------
------>
view-148
<------
------>
transpose-149
<------
------>
clone-150
<------
------>
_unsafe_view-151
<------
          >>Linear-model.decoder.layers.2.self_attn.out_proj-35
------>
view-152
<------
------>
t-153
<------
------>
addmm-154
<------
------>
view-155
<------
          <<Linear-model.decoder.layers.2.self_attn.out_proj-35
        <<OPTAttention-model.decoder.layers.2.self_attn-31
------>
native_dropout-156
<------
------>
add-157
<------
        >>LayerNorm-model.decoder.layers.2.self_attn_layer_norm-37
------>
native_layer_norm-158
<------
        <<LayerNorm-model.decoder.layers.2.self_attn_layer_norm-37
------>
view-159
<------
        >>Linear-model.decoder.layers.2.fc1-38
------>
t-160
<------
------>
addmm-161
<------
        <<Linear-model.decoder.layers.2.fc1-38
        >>ReLU-model.decoder.layers.2.activation_fn-36
------>
relu-162
<------
        <<ReLU-model.decoder.layers.2.activation_fn-36
        >>Linear-model.decoder.layers.2.fc2-39
------>
t-163
<------
------>
addmm-164
<------
        <<Linear-model.decoder.layers.2.fc2-39
------>
native_dropout-165
<------
------>
add-166
<------
------>
view-167
<------
        >>LayerNorm-model.decoder.layers.2.final_layer_norm-40
------>
native_layer_norm-168
<------
        <<LayerNorm-model.decoder.layers.2.final_layer_norm-40
      <<OPTDecoderLayer-model.decoder.layers.2-30
      >>OPTDecoderLayer-model.decoder.layers.3-41
        >>OPTAttention-model.decoder.layers.3.self_attn-42
          >>Linear-model.decoder.layers.3.self_attn.q_proj-45
------>
view-169
<------
------>
t-170
<------
------>
addmm-171
<------
------>
view-172
<------
          <<Linear-model.decoder.layers.3.self_attn.q_proj-45
------>
mul-173
<------
          >>Linear-model.decoder.layers.3.self_attn.k_proj-43
------>
view-174
<------
------>
t-175
<------
------>
addmm-176
<------
------>
view-177
<------
          <<Linear-model.decoder.layers.3.self_attn.k_proj-43
------>
view-178
<------
------>
transpose-179
<------
------>
clone-180
<------
          >>Linear-model.decoder.layers.3.self_attn.v_proj-44
------>
view-181
<------
------>
t-182
<------
------>
addmm-183
<------
------>
view-184
<------
          <<Linear-model.decoder.layers.3.self_attn.v_proj-44
------>
view-185
<------
------>
transpose-186
<------
------>
clone-187
<------
------>
view-188
<------
------>
transpose-189
<------
------>
clone-190
<------
------>
view-191
<------
------>
view-192
<------
------>
view-193
<------
------>
transpose-194
<------
------>
bmm-195
<------
------>
view-196
<------
------>
add-197
<------
------>
maximum-198
<------
------>
view-199
<------
------>
_softmax-200
<------
------>
bmm-201
<------
------>
view-202
<------
------>
transpose-203
<------
------>
clone-204
<------
------>
_unsafe_view-205
<------
          >>Linear-model.decoder.layers.3.self_attn.out_proj-46
------>
view-206
<------
------>
t-207
<------
------>
addmm-208
<------
------>
view-209
<------
          <<Linear-model.decoder.layers.3.self_attn.out_proj-46
        <<OPTAttention-model.decoder.layers.3.self_attn-42
------>
native_dropout-210
<------
------>
add-211
<------
        >>LayerNorm-model.decoder.layers.3.self_attn_layer_norm-48
------>
native_layer_norm-212
<------
        <<LayerNorm-model.decoder.layers.3.self_attn_layer_norm-48
------>
view-213
<------
        >>Linear-model.decoder.layers.3.fc1-49
------>
t-214
<------
------>
addmm-215
<------
        <<Linear-model.decoder.layers.3.fc1-49
        >>ReLU-model.decoder.layers.3.activation_fn-47
------>
relu-216
<------
        <<ReLU-model.decoder.layers.3.activation_fn-47
        >>Linear-model.decoder.layers.3.fc2-50
------>
t-217
<------
------>
addmm-218
<------
        <<Linear-model.decoder.layers.3.fc2-50
------>
native_dropout-219
<------
------>
add-220
<------
------>
view-221
<------
        >>LayerNorm-model.decoder.layers.3.final_layer_norm-51
------>
native_layer_norm-222
<------
        <<LayerNorm-model.decoder.layers.3.final_layer_norm-51
      <<OPTDecoderLayer-model.decoder.layers.3-41
      >>OPTDecoderLayer-model.decoder.layers.4-52
        >>OPTAttention-model.decoder.layers.4.self_attn-53
          >>Linear-model.decoder.layers.4.self_attn.q_proj-56
------>
view-223
<------
------>
t-224
<------
------>
addmm-225
<------
------>
view-226
<------
          <<Linear-model.decoder.layers.4.self_attn.q_proj-56
------>
mul-227
<------
          >>Linear-model.decoder.layers.4.self_attn.k_proj-54
------>
view-228
<------
------>
t-229
<------
------>
addmm-230
<------
------>
view-231
<------
          <<Linear-model.decoder.layers.4.self_attn.k_proj-54
------>
view-232
<------
------>
transpose-233
<------
------>
clone-234
<------
          >>Linear-model.decoder.layers.4.self_attn.v_proj-55
------>
view-235
<------
------>
t-236
<------
------>
addmm-237
<------
------>
view-238
<------
          <<Linear-model.decoder.layers.4.self_attn.v_proj-55
------>
view-239
<------
------>
transpose-240
<------
------>
clone-241
<------
------>
view-242
<------
------>
transpose-243
<------
------>
clone-244
<------
------>
view-245
<------
------>
view-246
<------
------>
view-247
<------
------>
transpose-248
<------
------>
bmm-249
<------
------>
view-250
<------
------>
add-251
<------
------>
maximum-252
<------
------>
view-253
<------
------>
_softmax-254
<------
------>
bmm-255
<------
------>
view-256
<------
------>
transpose-257
<------
------>
clone-258
<------
------>
_unsafe_view-259
<------
          >>Linear-model.decoder.layers.4.self_attn.out_proj-57
------>
view-260
<------
------>
t-261
<------
------>
addmm-262
<------
------>
view-263
<------
          <<Linear-model.decoder.layers.4.self_attn.out_proj-57
        <<OPTAttention-model.decoder.layers.4.self_attn-53
------>
native_dropout-264
<------
------>
add-265
<------
        >>LayerNorm-model.decoder.layers.4.self_attn_layer_norm-59
------>
native_layer_norm-266
<------
        <<LayerNorm-model.decoder.layers.4.self_attn_layer_norm-59
------>
view-267
<------
        >>Linear-model.decoder.layers.4.fc1-60
------>
t-268
<------
------>
addmm-269
<------
        <<Linear-model.decoder.layers.4.fc1-60
        >>ReLU-model.decoder.layers.4.activation_fn-58
------>
relu-270
<------
        <<ReLU-model.decoder.layers.4.activation_fn-58
        >>Linear-model.decoder.layers.4.fc2-61
------>
t-271
<------
------>
addmm-272
<------
        <<Linear-model.decoder.layers.4.fc2-61
------>
native_dropout-273
<------
------>
add-274
<------
------>
view-275
<------
        >>LayerNorm-model.decoder.layers.4.final_layer_norm-62
------>
native_layer_norm-276
<------
        <<LayerNorm-model.decoder.layers.4.final_layer_norm-62
      <<OPTDecoderLayer-model.decoder.layers.4-52
      >>OPTDecoderLayer-model.decoder.layers.5-63
        >>OPTAttention-model.decoder.layers.5.self_attn-64
          >>Linear-model.decoder.layers.5.self_attn.q_proj-67
------>
view-277
<------
------>
t-278
<------
------>
addmm-279
<------
------>
view-280
<------
          <<Linear-model.decoder.layers.5.self_attn.q_proj-67
------>
mul-281
<------
          >>Linear-model.decoder.layers.5.self_attn.k_proj-65
------>
view-282
<------
------>
t-283
<------
------>
addmm-284
<------
------>
view-285
<------
          <<Linear-model.decoder.layers.5.self_attn.k_proj-65
------>
view-286
<------
------>
transpose-287
<------
------>
clone-288
<------
          >>Linear-model.decoder.layers.5.self_attn.v_proj-66
------>
view-289
<------
------>
t-290
<------
------>
addmm-291
<------
------>
view-292
<------
          <<Linear-model.decoder.layers.5.self_attn.v_proj-66
------>
view-293
<------
------>
transpose-294
<------
------>
clone-295
<------
------>
view-296
<------
------>
transpose-297
<------
------>
clone-298
<------
------>
view-299
<------
------>
view-300
<------
------>
view-301
<------
------>
transpose-302
<------
------>
bmm-303
<------
------>
view-304
<------
------>
add-305
<------
------>
maximum-306
<------
------>
view-307
<------
------>
_softmax-308
<------
------>
bmm-309
<------
------>
view-310
<------
------>
transpose-311
<------
------>
clone-312
<------
------>
_unsafe_view-313
<------
          >>Linear-model.decoder.layers.5.self_attn.out_proj-68
------>
view-314
<------
------>
t-315
<------
------>
addmm-316
<------
------>
view-317
<------
          <<Linear-model.decoder.layers.5.self_attn.out_proj-68
        <<OPTAttention-model.decoder.layers.5.self_attn-64
------>
native_dropout-318
<------
------>
add-319
<------
        >>LayerNorm-model.decoder.layers.5.self_attn_layer_norm-70
------>
native_layer_norm-320
<------
        <<LayerNorm-model.decoder.layers.5.self_attn_layer_norm-70
------>
view-321
<------
        >>Linear-model.decoder.layers.5.fc1-71
------>
t-322
<------
------>
addmm-323
<------
        <<Linear-model.decoder.layers.5.fc1-71
        >>ReLU-model.decoder.layers.5.activation_fn-69
------>
relu-324
<------
        <<ReLU-model.decoder.layers.5.activation_fn-69
        >>Linear-model.decoder.layers.5.fc2-72
------>
t-325
<------
------>
addmm-326
<------
        <<Linear-model.decoder.layers.5.fc2-72
------>
native_dropout-327
<------
------>
add-328
<------
------>
view-329
<------
        >>LayerNorm-model.decoder.layers.5.final_layer_norm-73
------>
native_layer_norm-330
<------
        <<LayerNorm-model.decoder.layers.5.final_layer_norm-73
      <<OPTDecoderLayer-model.decoder.layers.5-63
      >>OPTDecoderLayer-model.decoder.layers.6-74
        >>OPTAttention-model.decoder.layers.6.self_attn-75
          >>Linear-model.decoder.layers.6.self_attn.q_proj-78
------>
view-331
<------
------>
t-332
<------
------>
addmm-333
<------
------>
view-334
<------
          <<Linear-model.decoder.layers.6.self_attn.q_proj-78
------>
mul-335
<------
          >>Linear-model.decoder.layers.6.self_attn.k_proj-76
------>
view-336
<------
------>
t-337
<------
------>
addmm-338
<------
------>
view-339
<------
          <<Linear-model.decoder.layers.6.self_attn.k_proj-76
------>
view-340
<------
------>
transpose-341
<------
------>
clone-342
<------
          >>Linear-model.decoder.layers.6.self_attn.v_proj-77
------>
view-343
<------
------>
t-344
<------
------>
addmm-345
<------
------>
view-346
<------
          <<Linear-model.decoder.layers.6.self_attn.v_proj-77
------>
view-347
<------
------>
transpose-348
<------
------>
clone-349
<------
------>
view-350
<------
------>
transpose-351
<------
------>
clone-352
<------
------>
view-353
<------
------>
view-354
<------
------>
view-355
<------
------>
transpose-356
<------
------>
bmm-357
<------
------>
view-358
<------
------>
add-359
<------
------>
maximum-360
<------
------>
view-361
<------
------>
_softmax-362
<------
------>
bmm-363
<------
------>
view-364
<------
------>
transpose-365
<------
------>
clone-366
<------
------>
_unsafe_view-367
<------
          >>Linear-model.decoder.layers.6.self_attn.out_proj-79
------>
view-368
<------
------>
t-369
<------
------>
addmm-370
<------
------>
view-371
<------
          <<Linear-model.decoder.layers.6.self_attn.out_proj-79
        <<OPTAttention-model.decoder.layers.6.self_attn-75
------>
native_dropout-372
<------
------>
add-373
<------
        >>LayerNorm-model.decoder.layers.6.self_attn_layer_norm-81
------>
native_layer_norm-374
<------
        <<LayerNorm-model.decoder.layers.6.self_attn_layer_norm-81
------>
view-375
<------
        >>Linear-model.decoder.layers.6.fc1-82
------>
t-376
<------
------>
addmm-377
<------
        <<Linear-model.decoder.layers.6.fc1-82
        >>ReLU-model.decoder.layers.6.activation_fn-80
------>
relu-378
<------
        <<ReLU-model.decoder.layers.6.activation_fn-80
        >>Linear-model.decoder.layers.6.fc2-83
------>
t-379
<------
------>
addmm-380
<------
        <<Linear-model.decoder.layers.6.fc2-83
------>
native_dropout-381
<------
------>
add-382
<------
------>
view-383
<------
        >>LayerNorm-model.decoder.layers.6.final_layer_norm-84
------>
native_layer_norm-384
<------
        <<LayerNorm-model.decoder.layers.6.final_layer_norm-84
      <<OPTDecoderLayer-model.decoder.layers.6-74
      >>OPTDecoderLayer-model.decoder.layers.7-85
        >>OPTAttention-model.decoder.layers.7.self_attn-86
          >>Linear-model.decoder.layers.7.self_attn.q_proj-89
------>
view-385
<------
------>
t-386
<------
------>
addmm-387
<------
------>
view-388
<------
          <<Linear-model.decoder.layers.7.self_attn.q_proj-89
------>
mul-389
<------
          >>Linear-model.decoder.layers.7.self_attn.k_proj-87
------>
view-390
<------
------>
t-391
<------
------>
addmm-392
<------
------>
view-393
<------
          <<Linear-model.decoder.layers.7.self_attn.k_proj-87
------>
view-394
<------
------>
transpose-395
<------
------>
clone-396
<------
          >>Linear-model.decoder.layers.7.self_attn.v_proj-88
------>
view-397
<------
------>
t-398
<------
------>
addmm-399
<------
------>
view-400
<------
          <<Linear-model.decoder.layers.7.self_attn.v_proj-88
------>
view-401
<------
------>
transpose-402
<------
------>
clone-403
<------
------>
view-404
<------
------>
transpose-405
<------
------>
clone-406
<------
------>
view-407
<------
------>
view-408
<------
------>
view-409
<------
------>
transpose-410
<------
------>
bmm-411
<------
------>
view-412
<------
------>
add-413
<------
------>
maximum-414
<------
------>
view-415
<------
------>
_softmax-416
<------
------>
bmm-417
<------
------>
view-418
<------
------>
transpose-419
<------
------>
clone-420
<------
------>
_unsafe_view-421
<------
          >>Linear-model.decoder.layers.7.self_attn.out_proj-90
------>
view-422
<------
------>
t-423
<------
------>
addmm-424
<------
------>
view-425
<------
          <<Linear-model.decoder.layers.7.self_attn.out_proj-90
        <<OPTAttention-model.decoder.layers.7.self_attn-86
------>
native_dropout-426
<------
------>
add-427
<------
        >>LayerNorm-model.decoder.layers.7.self_attn_layer_norm-92
------>
native_layer_norm-428
<------
        <<LayerNorm-model.decoder.layers.7.self_attn_layer_norm-92
------>
view-429
<------
        >>Linear-model.decoder.layers.7.fc1-93
------>
t-430
<------
------>
addmm-431
<------
        <<Linear-model.decoder.layers.7.fc1-93
        >>ReLU-model.decoder.layers.7.activation_fn-91
------>
relu-432
<------
        <<ReLU-model.decoder.layers.7.activation_fn-91
        >>Linear-model.decoder.layers.7.fc2-94
------>
t-433
<------
------>
addmm-434
<------
        <<Linear-model.decoder.layers.7.fc2-94
------>
native_dropout-435
<------
------>
add-436
<------
------>
view-437
<------
        >>LayerNorm-model.decoder.layers.7.final_layer_norm-95
------>
native_layer_norm-438
<------
        <<LayerNorm-model.decoder.layers.7.final_layer_norm-95
      <<OPTDecoderLayer-model.decoder.layers.7-85
      >>OPTDecoderLayer-model.decoder.layers.8-96
        >>OPTAttention-model.decoder.layers.8.self_attn-97
          >>Linear-model.decoder.layers.8.self_attn.q_proj-100
------>
view-439
<------
------>
t-440
<------
------>
addmm-441
<------
------>
view-442
<------
          <<Linear-model.decoder.layers.8.self_attn.q_proj-100
------>
mul-443
<------
          >>Linear-model.decoder.layers.8.self_attn.k_proj-98
------>
view-444
<------
------>
t-445
<------
------>
addmm-446
<------
------>
view-447
<------
          <<Linear-model.decoder.layers.8.self_attn.k_proj-98
------>
view-448
<------
------>
transpose-449
<------
------>
clone-450
<------
          >>Linear-model.decoder.layers.8.self_attn.v_proj-99
------>
view-451
<------
------>
t-452
<------
------>
addmm-453
<------
------>
view-454
<------
          <<Linear-model.decoder.layers.8.self_attn.v_proj-99
------>
view-455
<------
------>
transpose-456
<------
------>
clone-457
<------
------>
view-458
<------
------>
transpose-459
<------
------>
clone-460
<------
------>
view-461
<------
------>
view-462
<------
------>
view-463
<------
------>
transpose-464
<------
------>
bmm-465
<------
------>
view-466
<------
------>
add-467
<------
------>
maximum-468
<------
------>
view-469
<------
------>
_softmax-470
<------
------>
bmm-471
<------
------>
view-472
<------
------>
transpose-473
<------
------>
clone-474
<------
------>
_unsafe_view-475
<------
          >>Linear-model.decoder.layers.8.self_attn.out_proj-101
------>
view-476
<------
------>
t-477
<------
------>
addmm-478
<------
------>
view-479
<------
          <<Linear-model.decoder.layers.8.self_attn.out_proj-101
        <<OPTAttention-model.decoder.layers.8.self_attn-97
------>
native_dropout-480
<------
------>
add-481
<------
        >>LayerNorm-model.decoder.layers.8.self_attn_layer_norm-103
------>
native_layer_norm-482
<------
        <<LayerNorm-model.decoder.layers.8.self_attn_layer_norm-103
------>
view-483
<------
        >>Linear-model.decoder.layers.8.fc1-104
------>
t-484
<------
------>
addmm-485
<------
        <<Linear-model.decoder.layers.8.fc1-104
        >>ReLU-model.decoder.layers.8.activation_fn-102
------>
relu-486
<------
        <<ReLU-model.decoder.layers.8.activation_fn-102
        >>Linear-model.decoder.layers.8.fc2-105
------>
t-487
<------
------>
addmm-488
<------
        <<Linear-model.decoder.layers.8.fc2-105
------>
native_dropout-489
<------
------>
add-490
<------
------>
view-491
<------
        >>LayerNorm-model.decoder.layers.8.final_layer_norm-106
------>
native_layer_norm-492
<------
        <<LayerNorm-model.decoder.layers.8.final_layer_norm-106
      <<OPTDecoderLayer-model.decoder.layers.8-96
      >>OPTDecoderLayer-model.decoder.layers.9-107
        >>OPTAttention-model.decoder.layers.9.self_attn-108
          >>Linear-model.decoder.layers.9.self_attn.q_proj-111
------>
view-493
<------
------>
t-494
<------
------>
addmm-495
<------
------>
view-496
<------
          <<Linear-model.decoder.layers.9.self_attn.q_proj-111
------>
mul-497
<------
          >>Linear-model.decoder.layers.9.self_attn.k_proj-109
------>
view-498
<------
------>
t-499
<------
------>
addmm-500
<------
------>
view-501
<------
          <<Linear-model.decoder.layers.9.self_attn.k_proj-109
------>
view-502
<------
------>
transpose-503
<------
------>
clone-504
<------
          >>Linear-model.decoder.layers.9.self_attn.v_proj-110
------>
view-505
<------
------>
t-506
<------
------>
addmm-507
<------
------>
view-508
<------
          <<Linear-model.decoder.layers.9.self_attn.v_proj-110
------>
view-509
<------
------>
transpose-510
<------
------>
clone-511
<------
------>
view-512
<------
------>
transpose-513
<------
------>
clone-514
<------
------>
view-515
<------
------>
view-516
<------
------>
view-517
<------
------>
transpose-518
<------
------>
bmm-519
<------
------>
view-520
<------
------>
add-521
<------
------>
maximum-522
<------
------>
view-523
<------
------>
_softmax-524
<------
------>
bmm-525
<------
------>
view-526
<------
------>
transpose-527
<------
------>
clone-528
<------
------>
_unsafe_view-529
<------
          >>Linear-model.decoder.layers.9.self_attn.out_proj-112
------>
view-530
<------
------>
t-531
<------
------>
addmm-532
<------
------>
view-533
<------
          <<Linear-model.decoder.layers.9.self_attn.out_proj-112
        <<OPTAttention-model.decoder.layers.9.self_attn-108
------>
native_dropout-534
<------
------>
add-535
<------
        >>LayerNorm-model.decoder.layers.9.self_attn_layer_norm-114
------>
native_layer_norm-536
<------
        <<LayerNorm-model.decoder.layers.9.self_attn_layer_norm-114
------>
view-537
<------
        >>Linear-model.decoder.layers.9.fc1-115
------>
t-538
<------
------>
addmm-539
<------
        <<Linear-model.decoder.layers.9.fc1-115
        >>ReLU-model.decoder.layers.9.activation_fn-113
------>
relu-540
<------
        <<ReLU-model.decoder.layers.9.activation_fn-113
        >>Linear-model.decoder.layers.9.fc2-116
------>
t-541
<------
------>
addmm-542
<------
        <<Linear-model.decoder.layers.9.fc2-116
------>
native_dropout-543
<------
------>
add-544
<------
------>
view-545
<------
        >>LayerNorm-model.decoder.layers.9.final_layer_norm-117
------>
native_layer_norm-546
<------
        <<LayerNorm-model.decoder.layers.9.final_layer_norm-117
      <<OPTDecoderLayer-model.decoder.layers.9-107
      >>OPTDecoderLayer-model.decoder.layers.10-118
        >>OPTAttention-model.decoder.layers.10.self_attn-119
          >>Linear-model.decoder.layers.10.self_attn.q_proj-122
------>
view-547
<------
------>
t-548
<------
------>
addmm-549
<------
------>
view-550
<------
          <<Linear-model.decoder.layers.10.self_attn.q_proj-122
------>
mul-551
<------
          >>Linear-model.decoder.layers.10.self_attn.k_proj-120
------>
view-552
<------
------>
t-553
<------
------>
addmm-554
<------
------>
view-555
<------
          <<Linear-model.decoder.layers.10.self_attn.k_proj-120
------>
view-556
<------
------>
transpose-557
<------
------>
clone-558
<------
          >>Linear-model.decoder.layers.10.self_attn.v_proj-121
------>
view-559
<------
------>
t-560
<------
------>
addmm-561
<------
------>
view-562
<------
          <<Linear-model.decoder.layers.10.self_attn.v_proj-121
------>
view-563
<------
------>
transpose-564
<------
------>
clone-565
<------
------>
view-566
<------
------>
transpose-567
<------
------>
clone-568
<------
------>
view-569
<------
------>
view-570
<------
------>
view-571
<------
------>
transpose-572
<------
------>
bmm-573
<------
------>
view-574
<------
------>
add-575
<------
------>
maximum-576
<------
------>
view-577
<------
------>
_softmax-578
<------
------>
bmm-579
<------
------>
view-580
<------
------>
transpose-581
<------
------>
clone-582
<------
------>
_unsafe_view-583
<------
          >>Linear-model.decoder.layers.10.self_attn.out_proj-123
------>
view-584
<------
------>
t-585
<------
------>
addmm-586
<------
------>
view-587
<------
          <<Linear-model.decoder.layers.10.self_attn.out_proj-123
        <<OPTAttention-model.decoder.layers.10.self_attn-119
------>
native_dropout-588
<------
------>
add-589
<------
        >>LayerNorm-model.decoder.layers.10.self_attn_layer_norm-125
------>
native_layer_norm-590
<------
        <<LayerNorm-model.decoder.layers.10.self_attn_layer_norm-125
------>
view-591
<------
        >>Linear-model.decoder.layers.10.fc1-126
------>
t-592
<------
------>
addmm-593
<------
        <<Linear-model.decoder.layers.10.fc1-126
        >>ReLU-model.decoder.layers.10.activation_fn-124
------>
relu-594
<------
        <<ReLU-model.decoder.layers.10.activation_fn-124
        >>Linear-model.decoder.layers.10.fc2-127
------>
t-595
<------
------>
addmm-596
<------
        <<Linear-model.decoder.layers.10.fc2-127
------>
native_dropout-597
<------
------>
add-598
<------
------>
view-599
<------
        >>LayerNorm-model.decoder.layers.10.final_layer_norm-128
------>
native_layer_norm-600
<------
        <<LayerNorm-model.decoder.layers.10.final_layer_norm-128
      <<OPTDecoderLayer-model.decoder.layers.10-118
      >>OPTDecoderLayer-model.decoder.layers.11-129
        >>OPTAttention-model.decoder.layers.11.self_attn-130
          >>Linear-model.decoder.layers.11.self_attn.q_proj-133
------>
view-601
<------
------>
t-602
<------
------>
addmm-603
<------
------>
view-604
<------
          <<Linear-model.decoder.layers.11.self_attn.q_proj-133
------>
mul-605
<------
          >>Linear-model.decoder.layers.11.self_attn.k_proj-131
------>
view-606
<------
------>
t-607
<------
------>
addmm-608
<------
------>
view-609
<------
          <<Linear-model.decoder.layers.11.self_attn.k_proj-131
------>
view-610
<------
------>
transpose-611
<------
------>
clone-612
<------
          >>Linear-model.decoder.layers.11.self_attn.v_proj-132
------>
view-613
<------
------>
t-614
<------
------>
addmm-615
<------
------>
view-616
<------
          <<Linear-model.decoder.layers.11.self_attn.v_proj-132
------>
view-617
<------
------>
transpose-618
<------
------>
clone-619
<------
------>
view-620
<------
------>
transpose-621
<------
------>
clone-622
<------
------>
view-623
<------
------>
view-624
<------
------>
view-625
<------
------>
transpose-626
<------
------>
bmm-627
<------
------>
view-628
<------
------>
add-629
<------
------>
maximum-630
<------
------>
view-631
<------
------>
_softmax-632
<------
------>
bmm-633
<------
------>
view-634
<------
------>
transpose-635
<------
------>
clone-636
<------
------>
_unsafe_view-637
<------
          >>Linear-model.decoder.layers.11.self_attn.out_proj-134
------>
view-638
<------
------>
t-639
<------
------>
addmm-640
<------
------>
view-641
<------
          <<Linear-model.decoder.layers.11.self_attn.out_proj-134
        <<OPTAttention-model.decoder.layers.11.self_attn-130
------>
native_dropout-642
<------
------>
add-643
<------
        >>LayerNorm-model.decoder.layers.11.self_attn_layer_norm-136
------>
native_layer_norm-644
<------
        <<LayerNorm-model.decoder.layers.11.self_attn_layer_norm-136
------>
view-645
<------
        >>Linear-model.decoder.layers.11.fc1-137
------>
t-646
<------
------>
addmm-647
<------
        <<Linear-model.decoder.layers.11.fc1-137
        >>ReLU-model.decoder.layers.11.activation_fn-135
------>
relu-648
<------
        <<ReLU-model.decoder.layers.11.activation_fn-135
        >>Linear-model.decoder.layers.11.fc2-138
------>
t-649
<------
------>
addmm-650
<------
        <<Linear-model.decoder.layers.11.fc2-138
------>
native_dropout-651
<------
------>
add-652
<------
------>
view-653
<------
        >>LayerNorm-model.decoder.layers.11.final_layer_norm-139
------>
native_layer_norm-654
<------
        <<LayerNorm-model.decoder.layers.11.final_layer_norm-139
      <<OPTDecoderLayer-model.decoder.layers.11-129
      >>OPTDecoderLayer-model.decoder.layers.12-140
        >>OPTAttention-model.decoder.layers.12.self_attn-141
          >>Linear-model.decoder.layers.12.self_attn.q_proj-144
------>
view-655
<------
------>
t-656
<------
------>
addmm-657
<------
------>
view-658
<------
          <<Linear-model.decoder.layers.12.self_attn.q_proj-144
------>
mul-659
<------
          >>Linear-model.decoder.layers.12.self_attn.k_proj-142
------>
view-660
<------
------>
t-661
<------
------>
addmm-662
<------
------>
view-663
<------
          <<Linear-model.decoder.layers.12.self_attn.k_proj-142
------>
view-664
<------
------>
transpose-665
<------
------>
clone-666
<------
          >>Linear-model.decoder.layers.12.self_attn.v_proj-143
------>
view-667
<------
------>
t-668
<------
------>
addmm-669
<------
------>
view-670
<------
          <<Linear-model.decoder.layers.12.self_attn.v_proj-143
------>
view-671
<------
------>
transpose-672
<------
------>
clone-673
<------
------>
view-674
<------
------>
transpose-675
<------
------>
clone-676
<------
------>
view-677
<------
------>
view-678
<------
------>
view-679
<------
------>
transpose-680
<------
------>
bmm-681
<------
------>
view-682
<------
------>
add-683
<------
------>
maximum-684
<------
------>
view-685
<------
------>
_softmax-686
<------
------>
bmm-687
<------
------>
view-688
<------
------>
transpose-689
<------
------>
clone-690
<------
------>
_unsafe_view-691
<------
          >>Linear-model.decoder.layers.12.self_attn.out_proj-145
------>
view-692
<------
------>
t-693
<------
------>
addmm-694
<------
------>
view-695
<------
          <<Linear-model.decoder.layers.12.self_attn.out_proj-145
        <<OPTAttention-model.decoder.layers.12.self_attn-141
------>
native_dropout-696
<------
------>
add-697
<------
        >>LayerNorm-model.decoder.layers.12.self_attn_layer_norm-147
------>
native_layer_norm-698
<------
        <<LayerNorm-model.decoder.layers.12.self_attn_layer_norm-147
------>
view-699
<------
        >>Linear-model.decoder.layers.12.fc1-148
------>
t-700
<------
------>
addmm-701
<------
        <<Linear-model.decoder.layers.12.fc1-148
        >>ReLU-model.decoder.layers.12.activation_fn-146
------>
relu-702
<------
        <<ReLU-model.decoder.layers.12.activation_fn-146
        >>Linear-model.decoder.layers.12.fc2-149
------>
t-703
<------
------>
addmm-704
<------
        <<Linear-model.decoder.layers.12.fc2-149
------>
native_dropout-705
<------
------>
add-706
<------
------>
view-707
<------
        >>LayerNorm-model.decoder.layers.12.final_layer_norm-150
------>
native_layer_norm-708
<------
        <<LayerNorm-model.decoder.layers.12.final_layer_norm-150
      <<OPTDecoderLayer-model.decoder.layers.12-140
      >>OPTDecoderLayer-model.decoder.layers.13-151
        >>OPTAttention-model.decoder.layers.13.self_attn-152
          >>Linear-model.decoder.layers.13.self_attn.q_proj-155
------>
view-709
<------
------>
t-710
<------
------>
addmm-711
<------
------>
view-712
<------
          <<Linear-model.decoder.layers.13.self_attn.q_proj-155
------>
mul-713
<------
          >>Linear-model.decoder.layers.13.self_attn.k_proj-153
------>
view-714
<------
------>
t-715
<------
------>
addmm-716
<------
------>
view-717
<------
          <<Linear-model.decoder.layers.13.self_attn.k_proj-153
------>
view-718
<------
------>
transpose-719
<------
------>
clone-720
<------
          >>Linear-model.decoder.layers.13.self_attn.v_proj-154
------>
view-721
<------
------>
t-722
<------
------>
addmm-723
<------
------>
view-724
<------
          <<Linear-model.decoder.layers.13.self_attn.v_proj-154
------>
view-725
<------
------>
transpose-726
<------
------>
clone-727
<------
------>
view-728
<------
------>
transpose-729
<------
------>
clone-730
<------
------>
view-731
<------
------>
view-732
<------
------>
view-733
<------
------>
transpose-734
<------
------>
bmm-735
<------
------>
view-736
<------
------>
add-737
<------
------>
maximum-738
<------
------>
view-739
<------
------>
_softmax-740
<------
------>
bmm-741
<------
------>
view-742
<------
------>
transpose-743
<------
------>
clone-744
<------
------>
_unsafe_view-745
<------
          >>Linear-model.decoder.layers.13.self_attn.out_proj-156
------>
view-746
<------
------>
t-747
<------
------>
addmm-748
<------
------>
view-749
<------
          <<Linear-model.decoder.layers.13.self_attn.out_proj-156
        <<OPTAttention-model.decoder.layers.13.self_attn-152
------>
native_dropout-750
<------
------>
add-751
<------
        >>LayerNorm-model.decoder.layers.13.self_attn_layer_norm-158
------>
native_layer_norm-752
<------
        <<LayerNorm-model.decoder.layers.13.self_attn_layer_norm-158
------>
view-753
<------
        >>Linear-model.decoder.layers.13.fc1-159
------>
t-754
<------
------>
addmm-755
<------
        <<Linear-model.decoder.layers.13.fc1-159
        >>ReLU-model.decoder.layers.13.activation_fn-157
------>
relu-756
<------
        <<ReLU-model.decoder.layers.13.activation_fn-157
        >>Linear-model.decoder.layers.13.fc2-160
------>
t-757
<------
------>
addmm-758
<------
        <<Linear-model.decoder.layers.13.fc2-160
------>
native_dropout-759
<------
------>
add-760
<------
------>
view-761
<------
        >>LayerNorm-model.decoder.layers.13.final_layer_norm-161
------>
native_layer_norm-762
<------
        <<LayerNorm-model.decoder.layers.13.final_layer_norm-161
      <<OPTDecoderLayer-model.decoder.layers.13-151
      >>OPTDecoderLayer-model.decoder.layers.14-162
        >>OPTAttention-model.decoder.layers.14.self_attn-163
          >>Linear-model.decoder.layers.14.self_attn.q_proj-166
------>
view-763
<------
------>
t-764
<------
------>
addmm-765
<------
------>
view-766
<------
          <<Linear-model.decoder.layers.14.self_attn.q_proj-166
------>
mul-767
<------
          >>Linear-model.decoder.layers.14.self_attn.k_proj-164
------>
view-768
<------
------>
t-769
<------
------>
addmm-770
<------
------>
view-771
<------
          <<Linear-model.decoder.layers.14.self_attn.k_proj-164
------>
view-772
<------
------>
transpose-773
<------
------>
clone-774
<------
          >>Linear-model.decoder.layers.14.self_attn.v_proj-165
------>
view-775
<------
------>
t-776
<------
------>
addmm-777
<------
------>
view-778
<------
          <<Linear-model.decoder.layers.14.self_attn.v_proj-165
------>
view-779
<------
------>
transpose-780
<------
------>
clone-781
<------
------>
view-782
<------
------>
transpose-783
<------
------>
clone-784
<------
------>
view-785
<------
------>
view-786
<------
------>
view-787
<------
------>
transpose-788
<------
------>
bmm-789
<------
------>
view-790
<------
------>
add-791
<------
------>
maximum-792
<------
------>
view-793
<------
------>
_softmax-794
<------
------>
bmm-795
<------
------>
view-796
<------
------>
transpose-797
<------
------>
clone-798
<------
------>
_unsafe_view-799
<------
          >>Linear-model.decoder.layers.14.self_attn.out_proj-167
------>
view-800
<------
------>
t-801
<------
------>
addmm-802
<------
------>
view-803
<------
          <<Linear-model.decoder.layers.14.self_attn.out_proj-167
        <<OPTAttention-model.decoder.layers.14.self_attn-163
------>
native_dropout-804
<------
------>
add-805
<------
        >>LayerNorm-model.decoder.layers.14.self_attn_layer_norm-169
------>
native_layer_norm-806
<------
        <<LayerNorm-model.decoder.layers.14.self_attn_layer_norm-169
------>
view-807
<------
        >>Linear-model.decoder.layers.14.fc1-170
------>
t-808
<------
------>
addmm-809
<------
        <<Linear-model.decoder.layers.14.fc1-170
        >>ReLU-model.decoder.layers.14.activation_fn-168
------>
relu-810
<------
        <<ReLU-model.decoder.layers.14.activation_fn-168
        >>Linear-model.decoder.layers.14.fc2-171
------>
t-811
<------
------>
addmm-812
<------
        <<Linear-model.decoder.layers.14.fc2-171
------>
native_dropout-813
<------
------>
add-814
<------
------>
view-815
<------
        >>LayerNorm-model.decoder.layers.14.final_layer_norm-172
------>
native_layer_norm-816
<------
        <<LayerNorm-model.decoder.layers.14.final_layer_norm-172
      <<OPTDecoderLayer-model.decoder.layers.14-162
      >>OPTDecoderLayer-model.decoder.layers.15-173
        >>OPTAttention-model.decoder.layers.15.self_attn-174
          >>Linear-model.decoder.layers.15.self_attn.q_proj-177
------>
view-817
<------
------>
t-818
<------
------>
addmm-819
<------
------>
view-820
<------
          <<Linear-model.decoder.layers.15.self_attn.q_proj-177
------>
mul-821
<------
          >>Linear-model.decoder.layers.15.self_attn.k_proj-175
------>
view-822
<------
------>
t-823
<------
------>
addmm-824
<------
------>
view-825
<------
          <<Linear-model.decoder.layers.15.self_attn.k_proj-175
------>
view-826
<------
------>
transpose-827
<------
------>
clone-828
<------
          >>Linear-model.decoder.layers.15.self_attn.v_proj-176
------>
view-829
<------
------>
t-830
<------
------>
addmm-831
<------
------>
view-832
<------
          <<Linear-model.decoder.layers.15.self_attn.v_proj-176
------>
view-833
<------
------>
transpose-834
<------
------>
clone-835
<------
------>
view-836
<------
------>
transpose-837
<------
------>
clone-838
<------
------>
view-839
<------
------>
view-840
<------
------>
view-841
<------
------>
transpose-842
<------
------>
bmm-843
<------
------>
view-844
<------
------>
add-845
<------
------>
maximum-846
<------
------>
view-847
<------
------>
_softmax-848
<------
------>
bmm-849
<------
------>
view-850
<------
------>
transpose-851
<------
------>
clone-852
<------
------>
_unsafe_view-853
<------
          >>Linear-model.decoder.layers.15.self_attn.out_proj-178
------>
view-854
<------
------>
t-855
<------
------>
addmm-856
<------
------>
view-857
<------
          <<Linear-model.decoder.layers.15.self_attn.out_proj-178
        <<OPTAttention-model.decoder.layers.15.self_attn-174
------>
native_dropout-858
<------
------>
add-859
<------
        >>LayerNorm-model.decoder.layers.15.self_attn_layer_norm-180
------>
native_layer_norm-860
<------
        <<LayerNorm-model.decoder.layers.15.self_attn_layer_norm-180
------>
view-861
<------
        >>Linear-model.decoder.layers.15.fc1-181
------>
t-862
<------
------>
addmm-863
<------
        <<Linear-model.decoder.layers.15.fc1-181
        >>ReLU-model.decoder.layers.15.activation_fn-179
------>
relu-864
<------
        <<ReLU-model.decoder.layers.15.activation_fn-179
        >>Linear-model.decoder.layers.15.fc2-182
------>
t-865
<------
------>
addmm-866
<------
        <<Linear-model.decoder.layers.15.fc2-182
------>
native_dropout-867
<------
------>
add-868
<------
------>
view-869
<------
        >>LayerNorm-model.decoder.layers.15.final_layer_norm-183
------>
native_layer_norm-870
<------
        <<LayerNorm-model.decoder.layers.15.final_layer_norm-183
      <<OPTDecoderLayer-model.decoder.layers.15-173
      >>OPTDecoderLayer-model.decoder.layers.16-184
        >>OPTAttention-model.decoder.layers.16.self_attn-185
          >>Linear-model.decoder.layers.16.self_attn.q_proj-188
------>
view-871
<------
------>
t-872
<------
------>
addmm-873
<------
------>
view-874
<------
          <<Linear-model.decoder.layers.16.self_attn.q_proj-188
------>
mul-875
<------
          >>Linear-model.decoder.layers.16.self_attn.k_proj-186
------>
view-876
<------
------>
t-877
<------
------>
addmm-878
<------
------>
view-879
<------
          <<Linear-model.decoder.layers.16.self_attn.k_proj-186
------>
view-880
<------
------>
transpose-881
<------
------>
clone-882
<------
          >>Linear-model.decoder.layers.16.self_attn.v_proj-187
------>
view-883
<------
------>
t-884
<------
------>
addmm-885
<------
------>
view-886
<------
          <<Linear-model.decoder.layers.16.self_attn.v_proj-187
------>
view-887
<------
------>
transpose-888
<------
------>
clone-889
<------
------>
view-890
<------
------>
transpose-891
<------
------>
clone-892
<------
------>
view-893
<------
------>
view-894
<------
------>
view-895
<------
------>
transpose-896
<------
------>
bmm-897
<------
------>
view-898
<------
------>
add-899
<------
------>
maximum-900
<------
------>
view-901
<------
------>
_softmax-902
<------
------>
bmm-903
<------
------>
view-904
<------
------>
transpose-905
<------
------>
clone-906
<------
------>
_unsafe_view-907
<------
          >>Linear-model.decoder.layers.16.self_attn.out_proj-189
------>
view-908
<------
------>
t-909
<------
------>
addmm-910
<------
------>
view-911
<------
          <<Linear-model.decoder.layers.16.self_attn.out_proj-189
        <<OPTAttention-model.decoder.layers.16.self_attn-185
------>
native_dropout-912
<------
------>
add-913
<------
        >>LayerNorm-model.decoder.layers.16.self_attn_layer_norm-191
------>
native_layer_norm-914
<------
        <<LayerNorm-model.decoder.layers.16.self_attn_layer_norm-191
------>
view-915
<------
        >>Linear-model.decoder.layers.16.fc1-192
------>
t-916
<------
------>
addmm-917
<------
        <<Linear-model.decoder.layers.16.fc1-192
        >>ReLU-model.decoder.layers.16.activation_fn-190
------>
relu-918
<------
        <<ReLU-model.decoder.layers.16.activation_fn-190
        >>Linear-model.decoder.layers.16.fc2-193
------>
t-919
<------
------>
addmm-920
<------
        <<Linear-model.decoder.layers.16.fc2-193
------>
native_dropout-921
<------
------>
add-922
<------
------>
view-923
<------
        >>LayerNorm-model.decoder.layers.16.final_layer_norm-194
------>
native_layer_norm-924
<------
        <<LayerNorm-model.decoder.layers.16.final_layer_norm-194
      <<OPTDecoderLayer-model.decoder.layers.16-184
      >>OPTDecoderLayer-model.decoder.layers.17-195
        >>OPTAttention-model.decoder.layers.17.self_attn-196
          >>Linear-model.decoder.layers.17.self_attn.q_proj-199
------>
view-925
<------
------>
t-926
<------
------>
addmm-927
<------
------>
view-928
<------
          <<Linear-model.decoder.layers.17.self_attn.q_proj-199
------>
mul-929
<------
          >>Linear-model.decoder.layers.17.self_attn.k_proj-197
------>
view-930
<------
------>
t-931
<------
------>
addmm-932
<------
------>
view-933
<------
          <<Linear-model.decoder.layers.17.self_attn.k_proj-197
------>
view-934
<------
------>
transpose-935
<------
------>
clone-936
<------
          >>Linear-model.decoder.layers.17.self_attn.v_proj-198
------>
view-937
<------
------>
t-938
<------
------>
addmm-939
<------
------>
view-940
<------
          <<Linear-model.decoder.layers.17.self_attn.v_proj-198
------>
view-941
<------
------>
transpose-942
<------
------>
clone-943
<------
------>
view-944
<------
------>
transpose-945
<------
------>
clone-946
<------
------>
view-947
<------
------>
view-948
<------
------>
view-949
<------
------>
transpose-950
<------
------>
bmm-951
<------
------>
view-952
<------
------>
add-953
<------
------>
maximum-954
<------
------>
view-955
<------
------>
_softmax-956
<------
------>
bmm-957
<------
------>
view-958
<------
------>
transpose-959
<------
------>
clone-960
<------
------>
_unsafe_view-961
<------
          >>Linear-model.decoder.layers.17.self_attn.out_proj-200
------>
view-962
<------
------>
t-963
<------
------>
addmm-964
<------
------>
view-965
<------
          <<Linear-model.decoder.layers.17.self_attn.out_proj-200
        <<OPTAttention-model.decoder.layers.17.self_attn-196
------>
native_dropout-966
<------
------>
add-967
<------
        >>LayerNorm-model.decoder.layers.17.self_attn_layer_norm-202
------>
native_layer_norm-968
<------
        <<LayerNorm-model.decoder.layers.17.self_attn_layer_norm-202
------>
view-969
<------
        >>Linear-model.decoder.layers.17.fc1-203
------>
t-970
<------
------>
addmm-971
<------
        <<Linear-model.decoder.layers.17.fc1-203
        >>ReLU-model.decoder.layers.17.activation_fn-201
------>
relu-972
<------
        <<ReLU-model.decoder.layers.17.activation_fn-201
        >>Linear-model.decoder.layers.17.fc2-204
------>
t-973
<------
------>
addmm-974
<------
        <<Linear-model.decoder.layers.17.fc2-204
------>
native_dropout-975
<------
------>
add-976
<------
------>
view-977
<------
        >>LayerNorm-model.decoder.layers.17.final_layer_norm-205
------>
native_layer_norm-978
<------
        <<LayerNorm-model.decoder.layers.17.final_layer_norm-205
      <<OPTDecoderLayer-model.decoder.layers.17-195
      >>OPTDecoderLayer-model.decoder.layers.18-206
        >>OPTAttention-model.decoder.layers.18.self_attn-207
          >>Linear-model.decoder.layers.18.self_attn.q_proj-210
------>
view-979
<------
------>
t-980
<------
------>
addmm-981
<------
------>
view-982
<------
          <<Linear-model.decoder.layers.18.self_attn.q_proj-210
------>
mul-983
<------
          >>Linear-model.decoder.layers.18.self_attn.k_proj-208
------>
view-984
<------
------>
t-985
<------
------>
addmm-986
<------
------>
view-987
<------
          <<Linear-model.decoder.layers.18.self_attn.k_proj-208
------>
view-988
<------
------>
transpose-989
<------
------>
clone-990
<------
          >>Linear-model.decoder.layers.18.self_attn.v_proj-209
------>
view-991
<------
------>
t-992
<------
------>
addmm-993
<------
------>
view-994
<------
          <<Linear-model.decoder.layers.18.self_attn.v_proj-209
------>
view-995
<------
------>
transpose-996
<------
------>
clone-997
<------
------>
view-998
<------
------>
transpose-999
<------
------>
clone-1000
<------
------>
view-1001
<------
------>
view-1002
<------
------>
view-1003
<------
------>
transpose-1004
<------
------>
bmm-1005
<------
------>
view-1006
<------
------>
add-1007
<------
------>
maximum-1008
<------
------>
view-1009
<------
------>
_softmax-1010
<------
------>
bmm-1011
<------
------>
view-1012
<------
------>
transpose-1013
<------
------>
clone-1014
<------
------>
_unsafe_view-1015
<------
          >>Linear-model.decoder.layers.18.self_attn.out_proj-211
------>
view-1016
<------
------>
t-1017
<------
------>
addmm-1018
<------
------>
view-1019
<------
          <<Linear-model.decoder.layers.18.self_attn.out_proj-211
        <<OPTAttention-model.decoder.layers.18.self_attn-207
------>
native_dropout-1020
<------
------>
add-1021
<------
        >>LayerNorm-model.decoder.layers.18.self_attn_layer_norm-213
------>
native_layer_norm-1022
<------
        <<LayerNorm-model.decoder.layers.18.self_attn_layer_norm-213
------>
view-1023
<------
        >>Linear-model.decoder.layers.18.fc1-214
------>
t-1024
<------
------>
addmm-1025
<------
        <<Linear-model.decoder.layers.18.fc1-214
        >>ReLU-model.decoder.layers.18.activation_fn-212
------>
relu-1026
<------
        <<ReLU-model.decoder.layers.18.activation_fn-212
        >>Linear-model.decoder.layers.18.fc2-215
------>
t-1027
<------
------>
addmm-1028
<------
        <<Linear-model.decoder.layers.18.fc2-215
------>
native_dropout-1029
<------
------>
add-1030
<------
------>
view-1031
<------
        >>LayerNorm-model.decoder.layers.18.final_layer_norm-216
------>
native_layer_norm-1032
<------
        <<LayerNorm-model.decoder.layers.18.final_layer_norm-216
      <<OPTDecoderLayer-model.decoder.layers.18-206
      >>OPTDecoderLayer-model.decoder.layers.19-217
        >>OPTAttention-model.decoder.layers.19.self_attn-218
          >>Linear-model.decoder.layers.19.self_attn.q_proj-221
------>
view-1033
<------
------>
t-1034
<------
------>
addmm-1035
<------
------>
view-1036
<------
          <<Linear-model.decoder.layers.19.self_attn.q_proj-221
------>
mul-1037
<------
          >>Linear-model.decoder.layers.19.self_attn.k_proj-219
------>
view-1038
<------
------>
t-1039
<------
------>
addmm-1040
<------
------>
view-1041
<------
          <<Linear-model.decoder.layers.19.self_attn.k_proj-219
------>
view-1042
<------
------>
transpose-1043
<------
------>
clone-1044
<------
          >>Linear-model.decoder.layers.19.self_attn.v_proj-220
------>
view-1045
<------
------>
t-1046
<------
------>
addmm-1047
<------
------>
view-1048
<------
          <<Linear-model.decoder.layers.19.self_attn.v_proj-220
------>
view-1049
<------
------>
transpose-1050
<------
------>
clone-1051
<------
------>
view-1052
<------
------>
transpose-1053
<------
------>
clone-1054
<------
------>
view-1055
<------
------>
view-1056
<------
------>
view-1057
<------
------>
transpose-1058
<------
------>
bmm-1059
<------
------>
view-1060
<------
------>
add-1061
<------
------>
maximum-1062
<------
------>
view-1063
<------
------>
_softmax-1064
<------
------>
bmm-1065
<------
------>
view-1066
<------
------>
transpose-1067
<------
------>
clone-1068
<------
------>
_unsafe_view-1069
<------
          >>Linear-model.decoder.layers.19.self_attn.out_proj-222
------>
view-1070
<------
------>
t-1071
<------
------>
addmm-1072
<------
------>
view-1073
<------
          <<Linear-model.decoder.layers.19.self_attn.out_proj-222
        <<OPTAttention-model.decoder.layers.19.self_attn-218
------>
native_dropout-1074
<------
------>
add-1075
<------
        >>LayerNorm-model.decoder.layers.19.self_attn_layer_norm-224
------>
native_layer_norm-1076
<------
        <<LayerNorm-model.decoder.layers.19.self_attn_layer_norm-224
------>
view-1077
<------
        >>Linear-model.decoder.layers.19.fc1-225
------>
t-1078
<------
------>
addmm-1079
<------
        <<Linear-model.decoder.layers.19.fc1-225
        >>ReLU-model.decoder.layers.19.activation_fn-223
------>
relu-1080
<------
        <<ReLU-model.decoder.layers.19.activation_fn-223
        >>Linear-model.decoder.layers.19.fc2-226
------>
t-1081
<------
------>
addmm-1082
<------
        <<Linear-model.decoder.layers.19.fc2-226
------>
native_dropout-1083
<------
------>
add-1084
<------
------>
view-1085
<------
        >>LayerNorm-model.decoder.layers.19.final_layer_norm-227
------>
native_layer_norm-1086
<------
        <<LayerNorm-model.decoder.layers.19.final_layer_norm-227
      <<OPTDecoderLayer-model.decoder.layers.19-217
      >>OPTDecoderLayer-model.decoder.layers.20-228
        >>OPTAttention-model.decoder.layers.20.self_attn-229
          >>Linear-model.decoder.layers.20.self_attn.q_proj-232
------>
view-1087
<------
------>
t-1088
<------
------>
addmm-1089
<------
------>
view-1090
<------
          <<Linear-model.decoder.layers.20.self_attn.q_proj-232
------>
mul-1091
<------
          >>Linear-model.decoder.layers.20.self_attn.k_proj-230
------>
view-1092
<------
------>
t-1093
<------
------>
addmm-1094
<------
------>
view-1095
<------
          <<Linear-model.decoder.layers.20.self_attn.k_proj-230
------>
view-1096
<------
------>
transpose-1097
<------
------>
clone-1098
<------
          >>Linear-model.decoder.layers.20.self_attn.v_proj-231
------>
view-1099
<------
------>
t-1100
<------
------>
addmm-1101
<------
------>
view-1102
<------
          <<Linear-model.decoder.layers.20.self_attn.v_proj-231
------>
view-1103
<------
------>
transpose-1104
<------
------>
clone-1105
<------
------>
view-1106
<------
------>
transpose-1107
<------
------>
clone-1108
<------
------>
view-1109
<------
------>
view-1110
<------
------>
view-1111
<------
------>
transpose-1112
<------
------>
bmm-1113
<------
------>
view-1114
<------
------>
add-1115
<------
------>
maximum-1116
<------
------>
view-1117
<------
------>
_softmax-1118
<------
------>
bmm-1119
<------
------>
view-1120
<------
------>
transpose-1121
<------
------>
clone-1122
<------
------>
_unsafe_view-1123
<------
          >>Linear-model.decoder.layers.20.self_attn.out_proj-233
------>
view-1124
<------
------>
t-1125
<------
------>
addmm-1126
<------
------>
view-1127
<------
          <<Linear-model.decoder.layers.20.self_attn.out_proj-233
        <<OPTAttention-model.decoder.layers.20.self_attn-229
------>
native_dropout-1128
<------
------>
add-1129
<------
        >>LayerNorm-model.decoder.layers.20.self_attn_layer_norm-235
------>
native_layer_norm-1130
<------
        <<LayerNorm-model.decoder.layers.20.self_attn_layer_norm-235
------>
view-1131
<------
        >>Linear-model.decoder.layers.20.fc1-236
------>
t-1132
<------
------>
addmm-1133
<------
        <<Linear-model.decoder.layers.20.fc1-236
        >>ReLU-model.decoder.layers.20.activation_fn-234
------>
relu-1134
<------
        <<ReLU-model.decoder.layers.20.activation_fn-234
        >>Linear-model.decoder.layers.20.fc2-237
------>
t-1135
<------
------>
addmm-1136
<------
        <<Linear-model.decoder.layers.20.fc2-237
------>
native_dropout-1137
<------
------>
add-1138
<------
------>
view-1139
<------
        >>LayerNorm-model.decoder.layers.20.final_layer_norm-238
------>
native_layer_norm-1140
<------
        <<LayerNorm-model.decoder.layers.20.final_layer_norm-238
      <<OPTDecoderLayer-model.decoder.layers.20-228
      >>OPTDecoderLayer-model.decoder.layers.21-239
        >>OPTAttention-model.decoder.layers.21.self_attn-240
          >>Linear-model.decoder.layers.21.self_attn.q_proj-243
------>
view-1141
<------
------>
t-1142
<------
------>
addmm-1143
<------
------>
view-1144
<------
          <<Linear-model.decoder.layers.21.self_attn.q_proj-243
------>
mul-1145
<------
          >>Linear-model.decoder.layers.21.self_attn.k_proj-241
------>
view-1146
<------
------>
t-1147
<------
------>
addmm-1148
<------
------>
view-1149
<------
          <<Linear-model.decoder.layers.21.self_attn.k_proj-241
------>
view-1150
<------
------>
transpose-1151
<------
------>
clone-1152
<------
          >>Linear-model.decoder.layers.21.self_attn.v_proj-242
------>
view-1153
<------
------>
t-1154
<------
------>
addmm-1155
<------
------>
view-1156
<------
          <<Linear-model.decoder.layers.21.self_attn.v_proj-242
------>
view-1157
<------
------>
transpose-1158
<------
------>
clone-1159
<------
------>
view-1160
<------
------>
transpose-1161
<------
------>
clone-1162
<------
------>
view-1163
<------
------>
view-1164
<------
------>
view-1165
<------
------>
transpose-1166
<------
------>
bmm-1167
<------
------>
view-1168
<------
------>
add-1169
<------
------>
maximum-1170
<------
------>
view-1171
<------
------>
_softmax-1172
<------
------>
bmm-1173
<------
------>
view-1174
<------
------>
transpose-1175
<------
------>
clone-1176
<------
------>
_unsafe_view-1177
<------
          >>Linear-model.decoder.layers.21.self_attn.out_proj-244
------>
view-1178
<------
------>
t-1179
<------
------>
addmm-1180
<------
------>
view-1181
<------
          <<Linear-model.decoder.layers.21.self_attn.out_proj-244
        <<OPTAttention-model.decoder.layers.21.self_attn-240
------>
native_dropout-1182
<------
------>
add-1183
<------
        >>LayerNorm-model.decoder.layers.21.self_attn_layer_norm-246
------>
native_layer_norm-1184
<------
        <<LayerNorm-model.decoder.layers.21.self_attn_layer_norm-246
------>
view-1185
<------
        >>Linear-model.decoder.layers.21.fc1-247
------>
t-1186
<------
------>
addmm-1187
<------
        <<Linear-model.decoder.layers.21.fc1-247
        >>ReLU-model.decoder.layers.21.activation_fn-245
------>
relu-1188
<------
        <<ReLU-model.decoder.layers.21.activation_fn-245
        >>Linear-model.decoder.layers.21.fc2-248
------>
t-1189
<------
------>
addmm-1190
<------
        <<Linear-model.decoder.layers.21.fc2-248
------>
native_dropout-1191
<------
------>
add-1192
<------
------>
view-1193
<------
        >>LayerNorm-model.decoder.layers.21.final_layer_norm-249
------>
native_layer_norm-1194
<------
        <<LayerNorm-model.decoder.layers.21.final_layer_norm-249
      <<OPTDecoderLayer-model.decoder.layers.21-239
      >>OPTDecoderLayer-model.decoder.layers.22-250
        >>OPTAttention-model.decoder.layers.22.self_attn-251
          >>Linear-model.decoder.layers.22.self_attn.q_proj-254
------>
view-1195
<------
------>
t-1196
<------
------>
addmm-1197
<------
------>
view-1198
<------
          <<Linear-model.decoder.layers.22.self_attn.q_proj-254
------>
mul-1199
<------
          >>Linear-model.decoder.layers.22.self_attn.k_proj-252
------>
view-1200
<------
------>
t-1201
<------
------>
addmm-1202
<------
------>
view-1203
<------
          <<Linear-model.decoder.layers.22.self_attn.k_proj-252
------>
view-1204
<------
------>
transpose-1205
<------
------>
clone-1206
<------
          >>Linear-model.decoder.layers.22.self_attn.v_proj-253
------>
view-1207
<------
------>
t-1208
<------
------>
addmm-1209
<------
------>
view-1210
<------
          <<Linear-model.decoder.layers.22.self_attn.v_proj-253
------>
view-1211
<------
------>
transpose-1212
<------
------>
clone-1213
<------
------>
view-1214
<------
------>
transpose-1215
<------
------>
clone-1216
<------
------>
view-1217
<------
------>
view-1218
<------
------>
view-1219
<------
------>
transpose-1220
<------
------>
bmm-1221
<------
------>
view-1222
<------
------>
add-1223
<------
------>
maximum-1224
<------
------>
view-1225
<------
------>
_softmax-1226
<------
------>
bmm-1227
<------
------>
view-1228
<------
------>
transpose-1229
<------
------>
clone-1230
<------
------>
_unsafe_view-1231
<------
          >>Linear-model.decoder.layers.22.self_attn.out_proj-255
------>
view-1232
<------
------>
t-1233
<------
------>
addmm-1234
<------
------>
view-1235
<------
          <<Linear-model.decoder.layers.22.self_attn.out_proj-255
        <<OPTAttention-model.decoder.layers.22.self_attn-251
------>
native_dropout-1236
<------
------>
add-1237
<------
        >>LayerNorm-model.decoder.layers.22.self_attn_layer_norm-257
------>
native_layer_norm-1238
<------
        <<LayerNorm-model.decoder.layers.22.self_attn_layer_norm-257
------>
view-1239
<------
        >>Linear-model.decoder.layers.22.fc1-258
------>
t-1240
<------
------>
addmm-1241
<------
        <<Linear-model.decoder.layers.22.fc1-258
        >>ReLU-model.decoder.layers.22.activation_fn-256
------>
relu-1242
<------
        <<ReLU-model.decoder.layers.22.activation_fn-256
        >>Linear-model.decoder.layers.22.fc2-259
------>
t-1243
<------
------>
addmm-1244
<------
        <<Linear-model.decoder.layers.22.fc2-259
------>
native_dropout-1245
<------
------>
add-1246
<------
------>
view-1247
<------
        >>LayerNorm-model.decoder.layers.22.final_layer_norm-260
------>
native_layer_norm-1248
<------
        <<LayerNorm-model.decoder.layers.22.final_layer_norm-260
      <<OPTDecoderLayer-model.decoder.layers.22-250
      >>OPTDecoderLayer-model.decoder.layers.23-261
        >>OPTAttention-model.decoder.layers.23.self_attn-262
          >>Linear-model.decoder.layers.23.self_attn.q_proj-265
------>
view-1249
<------
------>
t-1250
<------
------>
addmm-1251
<------
------>
view-1252
<------
          <<Linear-model.decoder.layers.23.self_attn.q_proj-265
------>
mul-1253
<------
          >>Linear-model.decoder.layers.23.self_attn.k_proj-263
------>
view-1254
<------
------>
t-1255
<------
------>
addmm-1256
<------
------>
view-1257
<------
          <<Linear-model.decoder.layers.23.self_attn.k_proj-263
------>
view-1258
<------
------>
transpose-1259
<------
------>
clone-1260
<------
          >>Linear-model.decoder.layers.23.self_attn.v_proj-264
------>
view-1261
<------
------>
t-1262
<------
------>
addmm-1263
<------
------>
view-1264
<------
          <<Linear-model.decoder.layers.23.self_attn.v_proj-264
------>
view-1265
<------
------>
transpose-1266
<------
------>
clone-1267
<------
------>
view-1268
<------
------>
transpose-1269
<------
------>
clone-1270
<------
------>
view-1271
<------
------>
view-1272
<------
------>
view-1273
<------
------>
transpose-1274
<------
------>
bmm-1275
<------
------>
view-1276
<------
------>
add-1277
<------
------>
maximum-1278
<------
------>
view-1279
<------
------>
_softmax-1280
<------
------>
bmm-1281
<------
------>
view-1282
<------
------>
transpose-1283
<------
------>
clone-1284
<------
------>
_unsafe_view-1285
<------
          >>Linear-model.decoder.layers.23.self_attn.out_proj-266
------>
view-1286
<------
------>
t-1287
<------
------>
addmm-1288
<------
------>
view-1289
<------
          <<Linear-model.decoder.layers.23.self_attn.out_proj-266
        <<OPTAttention-model.decoder.layers.23.self_attn-262
------>
native_dropout-1290
<------
------>
add-1291
<------
        >>LayerNorm-model.decoder.layers.23.self_attn_layer_norm-268
------>
native_layer_norm-1292
<------
        <<LayerNorm-model.decoder.layers.23.self_attn_layer_norm-268
------>
view-1293
<------
        >>Linear-model.decoder.layers.23.fc1-269
------>
t-1294
<------
------>
addmm-1295
<------
        <<Linear-model.decoder.layers.23.fc1-269
        >>ReLU-model.decoder.layers.23.activation_fn-267
------>
relu-1296
<------
        <<ReLU-model.decoder.layers.23.activation_fn-267
        >>Linear-model.decoder.layers.23.fc2-270
------>
t-1297
<------
------>
addmm-1298
<------
        <<Linear-model.decoder.layers.23.fc2-270
------>
native_dropout-1299
<------
------>
add-1300
<------
------>
view-1301
<------
        >>LayerNorm-model.decoder.layers.23.final_layer_norm-271
------>
native_layer_norm-1302
<------
        <<LayerNorm-model.decoder.layers.23.final_layer_norm-271
      <<OPTDecoderLayer-model.decoder.layers.23-261
    >>Linear-model.decoder.project_out-5
------>
t-1303
<------
------>
view-1304
<------
------>
mm-1305
<------
------>
_unsafe_view-1306
<------
    <<Linear-model.decoder.project_out-5
  <<OPTDecoder-model.decoder-2
>>Linear-lm_head-272
------>
t-1307
<------
------>
view-1308
<------
------>
mm-1309
<------
------>
_unsafe_view-1310
<------
<<Linear-lm_head-272
------>
slice-1311
<------
------>
slice-1312
<------
------>
clone-1313
<------
------>
view-1314
<------
------>
_log_softmax-1315
<------
------>
nll_loss_forward-1316
<------
<<OPTForCausalLM--0